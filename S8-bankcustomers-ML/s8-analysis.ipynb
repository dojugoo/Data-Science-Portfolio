{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project description - Supervised Learning\n",
    "\n",
    "Beta Bank customers are leaving: little by little, chipping away every month. The bankers figured out it’s cheaper to save the existing customers rather than to attract new ones.\n",
    "\n",
    "We need to predict whether a customer will leave the bank soon. You have the data on clients’ past behavior and termination of contracts with the bank.\n",
    "\n",
    "## Data description\n",
    "\n",
    "Data from the `/datasets/Churn.csv` file:\n",
    "\n",
    "Features\n",
    "- `RowNumber` — data string index\n",
    "- `CustomerId` — unique customer identifier\n",
    "- `Surname` — surname\n",
    "- `CreditScore` — credit score\n",
    "- `Geography` — country of residence\n",
    "- `Gender` — gender\n",
    "- `Age` — age\n",
    "- `Tenure` — period of maturation for a customer’s fixed deposit (years)\n",
    "- `Balance` — account balance\n",
    "- `NumOfProducts` — number of banking products used by the customer\n",
    "- `HasCrCard` — customer has a credit card\n",
    "- `IsActiveMember` — customer’s activeness\n",
    "- `EstimatedSalary` — estimated salary\n",
    "\n",
    "Target\n",
    "- `Exited` — сustomer has left\n",
    "\n",
    "## Overview of work process\n",
    "\n",
    "I present here a brief overview of how the data set was processed and analyzed. First, the data needs to be prepared prior to input for training models. Preparation of the data set included filling missing values, label encoding, and feature standardization. From here, models were trained without class balancing to get a sense of baseline metrics of the models. Techniques for class balancing, such as downsampling and upsampling, were used and then the different models were then optimized to find the best model in terms of accuracy for this data set. From this, we can determine the best model, and metrics were generated from the determined best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data into df dataframe\n",
    "df = pd.read_csv('Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "5     8.0  113755.78              2          1               0   \n",
       "6     7.0       0.00              2          1               1   \n",
       "7     4.0  115046.74              4          1               0   \n",
       "8     4.0  142051.07              2          0               1   \n",
       "9     2.0  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display information on the dataset\n",
    "df.info()\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts on the data set to prepare for training:\n",
    "- RowNumber, CustomerId, and Surname columns can be removed and not included as features because of their irrelevance to why someone would leave the bank. We don't want to train the models with these fields.\n",
    "- Missing values in the 'Tenure' column, will be investigated to determine the best way to address the missing values\n",
    "- Label encoding for the following columns: 'Geography', 'Gender'\n",
    "- Columns needing to be standardized or feature scaled: 'CreditScore', 'Age', 'Tenure', 'Balance', and 'EstimatedSalary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the RowNumber, CustomerId, and Surname columns\n",
    "data = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  1.  8.  7.  4.  6.  3. 10.  5.  9.  0. nan]\n",
      "4.997690023099769\n"
     ]
    }
   ],
   "source": [
    "# Investigating the Tenure column\n",
    "print(data['Tenure'].unique())\n",
    "print(data['Tenure'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenure column ranges from 0-10 with a mean value of 5. The missing values represent about 10% of the data. Plan is to fill the missing values with the mean of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing 'Tenure' values with the mean and convert to int type\n",
    "data['Tenure'] = data['Tenure'].fillna(5).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for the 'Geography' and 'Gender' columns\n",
    "data_ohe = pd.get_dummies(data, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data set into features and target\n",
    "features = data_ohe.drop('Exited', axis=1)\n",
    "target = data_ohe['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   CreditScore        10000 non-null  int64  \n",
      " 1   Age                10000 non-null  int64  \n",
      " 2   Tenure             10000 non-null  int64  \n",
      " 3   Balance            10000 non-null  float64\n",
      " 4   NumOfProducts      10000 non-null  int64  \n",
      " 5   HasCrCard          10000 non-null  int64  \n",
      " 6   IsActiveMember     10000 non-null  int64  \n",
      " 7   EstimatedSalary    10000 non-null  float64\n",
      " 8   Geography_Germany  10000 non-null  uint8  \n",
      " 9   Geography_Spain    10000 non-null  uint8  \n",
      " 10  Gender_Male        10000 non-null  uint8  \n",
      "dtypes: float64(2), int64(6), uint8(3)\n",
      "memory usage: 654.4 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.99790</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.545700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.76001</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.433553</td>\n",
       "      <td>0.431698</td>\n",
       "      <td>0.497932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CreditScore           Age       Tenure        Balance  NumOfProducts  \\\n",
       "count  10000.000000  10000.000000  10000.00000   10000.000000   10000.000000   \n",
       "mean     650.528800     38.921800      4.99790   76485.889288       1.530200   \n",
       "std       96.653299     10.487806      2.76001   62397.405202       0.581654   \n",
       "min      350.000000     18.000000      0.00000       0.000000       1.000000   \n",
       "25%      584.000000     32.000000      3.00000       0.000000       1.000000   \n",
       "50%      652.000000     37.000000      5.00000   97198.540000       1.000000   \n",
       "75%      718.000000     44.000000      7.00000  127644.240000       2.000000   \n",
       "max      850.000000     92.000000     10.00000  250898.090000       4.000000   \n",
       "\n",
       "         HasCrCard  IsActiveMember  EstimatedSalary  Geography_Germany  \\\n",
       "count  10000.00000    10000.000000     10000.000000       10000.000000   \n",
       "mean       0.70550        0.515100    100090.239881           0.250900   \n",
       "std        0.45584        0.499797     57510.492818           0.433553   \n",
       "min        0.00000        0.000000        11.580000           0.000000   \n",
       "25%        0.00000        0.000000     51002.110000           0.000000   \n",
       "50%        1.00000        1.000000    100193.915000           0.000000   \n",
       "75%        1.00000        1.000000    149388.247500           1.000000   \n",
       "max        1.00000        1.000000    199992.480000           1.000000   \n",
       "\n",
       "       Geography_Spain   Gender_Male  \n",
       "count     10000.000000  10000.000000  \n",
       "mean          0.247700      0.545700  \n",
       "std           0.431698      0.497932  \n",
       "min           0.000000      0.000000  \n",
       "25%           0.000000      0.000000  \n",
       "50%           0.000000      1.000000  \n",
       "75%           0.000000      1.000000  \n",
       "max           1.000000      1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check on the features dataset\n",
    "features.info()\n",
    "features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirming that data is transformed to what was expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data set into 60% training, 20% validation, and 20% test set\n",
    "features_train, features_split, target_train, target_split = train_test_split(\n",
    "    features, target, test_size=0.4, random_state=12345)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_split, target_split, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize columns\n",
    "cols_to_scale = ['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit to training set\n",
    "scaler.fit(features_train[cols_to_scale])\n",
    "\n",
    "# Transform to the sets\n",
    "pd.options.mode.chained_assignment = None\n",
    "features_train[cols_to_scale] = scaler.transform(features_train[cols_to_scale])\n",
    "features_valid[cols_to_scale] = scaler.transform(features_valid[cols_to_scale])\n",
    "features_test[cols_to_scale] = scaler.transform(features_test[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 11)\n",
      "(6000,)\n",
      "(2000, 11)\n",
      "(2000,)\n",
      "(2000, 11)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "# Confirm the splits by printing the sets\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's take a look at class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7963, 14)\n",
      "(2037, 14)\n"
     ]
    }
   ],
   "source": [
    "# Printing the number of target = 0, or target = 1\n",
    "print(df.query(\"Exited == 0\").shape)\n",
    "print(df.query(\"Exited == 1\").shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of 'negative' outcomes (customers staying with the bank) are 4x more than the 'positive' outcomes (customers leaving the bank). There is a class imbalance that will need to be addressed. First, the models will be trained without fixing the class imbalance to get a baseline of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial modeling without fixing class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree best depth: 6\n",
      "Accuracy on training set: 0.872, validation set: 0.858, test set: 0.848\n",
      "Confusion matrix: \n",
      "[[1528   54]\n",
      " [ 230  188]]\n",
      "Recall: 0.450, Precision: 0.777, F1: 0.570\n"
     ]
    }
   ],
   "source": [
    "# Evaluate data set using decision tree model\n",
    "# best_score = 0\n",
    "best_depth = 0\n",
    "best_f1 = 0\n",
    "for depth in range(1, 11):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    # score_valid = model.score(features_valid, target_valid)\n",
    "    predicted = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predicted)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_depth = depth\n",
    "\n",
    "# Use highest scoring model parameters to calculate metrics\n",
    "model_best = DecisionTreeClassifier(random_state=12345, max_depth=best_depth)\n",
    "model_best.fit(features_train, target_train)\n",
    "\n",
    "# Scoring accuracy on the different sets\n",
    "score_train = model_best.score(features_train, target_train)\n",
    "score_valid = model_best.score(features_valid, target_valid)\n",
    "score_test = model_best.score(features_test, target_test)\n",
    "\n",
    "# Calculating metrics\n",
    "predicted_valid = model_best.predict(features_valid) \n",
    "cf_matrix = confusion_matrix(target_valid, predicted_valid) # confusion matrix\n",
    "recall = recall_score(target_valid, predicted_valid) # recall\n",
    "precision = precision_score(target_valid, predicted_valid) # precision\n",
    "f1_sc = f1_score(target_valid, predicted_valid) # F1 score\n",
    "\n",
    "# Print output\n",
    "print(f'Decision Tree best depth: {best_depth}')\n",
    "print(f'Accuracy on training set: {score_train:.3f}, validation set: {score_valid:.3f}, test set: {score_test:.3f}')\n",
    "print(f'Confusion matrix: \\n{cf_matrix}')\n",
    "print(f'Recall: {recall:.3f}, Precision: {precision:.3f}, F1: {f1_sc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant model accuracy score: 0.791\n"
     ]
    }
   ],
   "source": [
    "# Sanity check with a constant model of all '0's (negative outcomes)\n",
    "constant_model = pd.Series(0, index=features_valid.index)\n",
    "score_constant = accuracy_score(constant_model, target_valid)\n",
    "print(f'Constant model accuracy score: {score_constant:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments on decision tree without class imbalance adjustments:\n",
    "\n",
    "At least the trained model has some improvement in the accuracy over the constant model. Also, accuracy is consistent between training, validation, and the test set. Even though the F1 score is close to our target (0.59), there are methods to try to improve this model even more when attempting to fix class imbalance.\n",
    "\n",
    "Next, let's evaluate the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression best solver: lbfgs\n",
      "Accuracy on training set: 0.819, validation set: 0.802, test set: 0.791\n",
      "Confusion matrix: \n",
      "[[1506   76]\n",
      " [ 320   98]]\n",
      "Recall: 0.234, Precision: 0.563, F1: 0.331\n",
      "Constant model accuracy score: 0.791\n"
     ]
    }
   ],
   "source": [
    "# Evaluate data set using logistic regression\n",
    "# best_score = 0\n",
    "best_solver = ''\n",
    "solvers = ['lbfgs', 'liblinear', 'newton-cg']\n",
    "best_f1 = 0\n",
    "for solv in solvers:\n",
    "    model = LogisticRegression(random_state=12345, solver=solv)\n",
    "    model.fit(features_train, target_train)\n",
    "    # score_valid = model.score(features_valid, target_valid)\n",
    "    predicted = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predicted)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_solver = solv\n",
    "\n",
    "# Use highest scoring model parameters to calculate metrics\n",
    "model_best = LogisticRegression(random_state=12345, solver=best_solver)\n",
    "model_best.fit(features_train, target_train)\n",
    "\n",
    "# Scoring accuracy on the different sets\n",
    "score_train = model_best.score(features_train, target_train)\n",
    "score_valid = model_best.score(features_valid, target_valid)\n",
    "score_test = model_best.score(features_test, target_test)\n",
    "\n",
    "# Calculating metrics\n",
    "predicted_valid = model_best.predict(features_valid) \n",
    "cf_matrix = confusion_matrix(target_valid, predicted_valid) # confusion matrix\n",
    "recall = recall_score(target_valid, predicted_valid) # recall\n",
    "precision = precision_score(target_valid, predicted_valid) # precision\n",
    "f1_sc = f1_score(target_valid, predicted_valid) # F1 score\n",
    "\n",
    "# Print output\n",
    "print(f'Logistic Regression best solver: {best_solver}')\n",
    "print(f'Accuracy on training set: {score_train:.3f}, validation set: {score_valid:.3f}, test set: {score_test:.3f}')\n",
    "print(f'Confusion matrix: \\n{cf_matrix}')\n",
    "print(f'Recall: {recall:.3f}, Precision: {precision:.3f}, F1: {f1_sc:.3f}')\n",
    "\n",
    "# Sanity check of the constant model\n",
    "print(f'Constant model accuracy score: {score_constant:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments on logistic regression:\n",
    "\n",
    "This performed very poorly, with the test set accuracy the same as the constant model. Also, the F1 score is very low with low recall and low precision. Not very good!\n",
    "\n",
    "Let's move on to the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest best n_estimator value: 20, max_depth: 9\n",
      "Accuracy on training set: 0.893, validation set: 0.864, test set: 0.846\n",
      "Confusion matrix: \n",
      "[[1543   39]\n",
      " [ 233  185]]\n",
      "Recall: 0.443, Precision: 0.826, F1: 0.576\n",
      "Constant model accuracy score: 0.791\n"
     ]
    }
   ],
   "source": [
    "# Evaluate data set using random forest\n",
    "# best_score = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "best_f1 = 0\n",
    "for est in range(20, 81, 10):\n",
    "    for depth in range(5, 10):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        model.fit(features_train, target_train)\n",
    "        # score_valid = model.score(features_valid, target_valid)\n",
    "        predicted = model.predict(features_valid)\n",
    "        f1 = f1_score(target_valid, predicted)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_depth = depth\n",
    "            best_est = est\n",
    "\n",
    "# Use highest scoring model parameters to calculate metrics\n",
    "model_best = RandomForestClassifier(random_state=12345, n_estimators=best_est, max_depth=best_depth)\n",
    "model_best.fit(features_train, target_train)\n",
    "\n",
    "# Scoring accuracy on the different sets\n",
    "score_train = model_best.score(features_train, target_train)\n",
    "score_valid = model_best.score(features_valid, target_valid)\n",
    "score_test = model_best.score(features_test, target_test)\n",
    "\n",
    "# Calculating metrics\n",
    "predicted_valid = model_best.predict(features_valid) \n",
    "cf_matrix = confusion_matrix(target_valid, predicted_valid) # confusion matrix\n",
    "recall = recall_score(target_valid, predicted_valid) # recall\n",
    "precision = precision_score(target_valid, predicted_valid) # precision\n",
    "f1_sc = f1_score(target_valid, predicted_valid) # F1 score\n",
    "\n",
    "# Print output\n",
    "print(f'Random Forest best n_estimator value: {best_est}, max_depth: {best_depth}')\n",
    "print(f'Accuracy on training set: {score_train:.3f}, validation set: {score_valid:.3f}, test set: {score_test:.3f}')\n",
    "print(f'Confusion matrix: \\n{cf_matrix}')\n",
    "print(f'Recall: {recall:.3f}, Precision: {precision:.3f}, F1: {f1_sc:.3f}')\n",
    "\n",
    "# Sanity check of the constant model\n",
    "print(f'Constant model accuracy score: {score_constant:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy and metrics with the random forest are similar to the decision tree results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample and Upsample for Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7963\n",
      "2037\n"
     ]
    }
   ],
   "source": [
    "# Printing out the lengths of the negative and positive outcomes for target\n",
    "print(len(target[target == 0]))\n",
    "print(len(target[target == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsample the negative class to 25%, and upsample the positive class 4x, and re-evaluate the models in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive class length:  (1201,)\n",
      "Negative class length:  (1196,)\n"
     ]
    }
   ],
   "source": [
    "# Downsample function\n",
    "def downsample(features, target, fraction):\n",
    "    # Split features and targets to 1 and 0\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    # downsample the negative class in features and concat to rest of features\n",
    "    features_zeros_downsampled = features_zeros.sample(frac=fraction, random_state=12345)\n",
    "    features_downsampled = pd.concat([features_zeros_downsampled] + [features_ones])\n",
    "\n",
    "    # downsample the target and concat to rest of target\n",
    "    target_zeros_downsampled = target_zeros.sample(frac=fraction, random_state=12345)\n",
    "    target_downsampled = pd.concat([target_zeros_downsampled] + [target_ones])\n",
    "\n",
    "    # Shuffle the resulting data\n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled)\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "# Downsample on the training data set\n",
    "features_train_downsampled, target_train_downsampled = downsample(features_train, target_train, 0.25)\n",
    "\n",
    "# Print out the resulting lengths to confirm downsampling\n",
    "print('Positive class length: ', target_train_downsampled[target_train_downsampled == 0].shape)\n",
    "print('Negative class length: ', target_train_downsampled[target_train_downsampled == 1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive class length:  (4804,)\n",
      "Negative class length:  (4784,)\n"
     ]
    }
   ],
   "source": [
    "# Upsample function\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    # Upsample the positive class by amount given by repeat\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    # Shuffle the resulting data\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "# Upsample on the training data set\n",
    "features_train_upsampled, target_train_upsampled = upsample(features_train, target_train, 4)\n",
    "\n",
    "# Print out the resulting lengths to confirm upsampling\n",
    "print('Positive class length: ', target_train_upsampled[target_train_upsampled == 0].shape)\n",
    "print('Negative class length: ', target_train_upsampled[target_train_upsampled == 1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lengths for both classes are fairly equal. Now let's train on these data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with downsampled training set best depth: 5\n",
      "Accuracy on training set: 0.799, validation set: 0.800, test set: 0.810\n",
      "Confusion matrix: \n",
      "[[1307  275]\n",
      " [ 125  293]]\n",
      "Recall: 0.701, Precision: 0.516, F1: 0.594\n",
      "Constant model accuracy score: 0.791\n"
     ]
    }
   ],
   "source": [
    "# Decision tree model on downsampled training data set\n",
    "best_score = 0\n",
    "best_depth = 0\n",
    "for depth in range(1, 11):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train_downsampled, target_train_downsampled)\n",
    "    score_valid = model.score(features_valid, target_valid)\n",
    "    if score_valid > best_score:\n",
    "        best_score = score_valid\n",
    "        best_depth = depth\n",
    "\n",
    "# Use highest scoring model parameters to calculate metrics\n",
    "model_best = DecisionTreeClassifier(random_state=12345, max_depth=best_depth)\n",
    "model_best.fit(features_train_downsampled, target_train_downsampled)\n",
    "\n",
    "# Scoring accuracy on the different sets\n",
    "score_train = model_best.score(features_train, target_train)\n",
    "score_valid = model_best.score(features_valid, target_valid)\n",
    "score_test = model_best.score(features_test, target_test)\n",
    "\n",
    "# Calculating metrics\n",
    "predicted_valid = model_best.predict(features_valid) \n",
    "cf_matrix = confusion_matrix(target_valid, predicted_valid) # confusion matrix\n",
    "recall = recall_score(target_valid, predicted_valid) # recall\n",
    "precision = precision_score(target_valid, predicted_valid) # precision\n",
    "f1_sc = f1_score(target_valid, predicted_valid) # F1 score\n",
    "\n",
    "# Print output\n",
    "print(f'Decision Tree with downsampled training set best depth: {best_depth}')\n",
    "print(f'Accuracy on training set: {score_train:.3f}, validation set: {score_valid:.3f}, test set: {score_test:.3f}')\n",
    "print(f'Confusion matrix: \\n{cf_matrix}')\n",
    "print(f'Recall: {recall:.3f}, Precision: {precision:.3f}, F1: {f1_sc:.3f}')\n",
    "\n",
    "# Sanity check with a constant model of all '0's (negative outcomes)\n",
    "print(f'Constant model accuracy score: {score_constant:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with upsampled training set best depth: 5\n",
      "Accuracy on training set: 0.807, validation set: 0.810, test set: 0.798\n",
      "Confusion matrix: \n",
      "[[1341  241]\n",
      " [ 138  280]]\n",
      "Recall: 0.670, Precision: 0.537, F1: 0.596\n",
      "Constant model accuracy score: 0.791\n"
     ]
    }
   ],
   "source": [
    "# Decision tree model on upsampled training data set\n",
    "best_score = 0\n",
    "best_depth = 0\n",
    "for depth in range(1, 11):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train_upsampled, target_train_upsampled)\n",
    "    score_valid = model.score(features_valid, target_valid)\n",
    "    if score_valid > best_score:\n",
    "        best_score = score_valid\n",
    "        best_depth = depth\n",
    "\n",
    "# Use highest scoring model parameters to calculate metrics\n",
    "model_best = DecisionTreeClassifier(random_state=12345, max_depth=best_depth)\n",
    "model_best.fit(features_train_upsampled, target_train_upsampled)\n",
    "\n",
    "# Scoring accuracy on the different sets\n",
    "score_train = model_best.score(features_train, target_train)\n",
    "score_valid = model_best.score(features_valid, target_valid)\n",
    "score_test = model_best.score(features_test, target_test)\n",
    "\n",
    "# Calculating metrics\n",
    "predicted_valid = model_best.predict(features_valid) \n",
    "cf_matrix = confusion_matrix(target_valid, predicted_valid) # confusion matrix\n",
    "recall = recall_score(target_valid, predicted_valid) # recall\n",
    "precision = precision_score(target_valid, predicted_valid) # precision\n",
    "f1_sc = f1_score(target_valid, predicted_valid) # F1 score\n",
    "\n",
    "# Print output\n",
    "print(f'Decision Tree with upsampled training set best depth: {best_depth}')\n",
    "print(f'Accuracy on training set: {score_train:.3f}, validation set: {score_valid:.3f}, test set: {score_test:.3f}')\n",
    "print(f'Confusion matrix: \\n{cf_matrix}')\n",
    "print(f'Recall: {recall:.3f}, Precision: {precision:.3f}, F1: {f1_sc:.3f}')\n",
    "\n",
    "# Sanity check with a constant model of all '0's (negative outcomes)\n",
    "print(f'Constant model accuracy score: {score_constant:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing between downsampling and upsampling, there's not significant differences. Accuracy between data sets are similar and F1 is close to equal.\n",
    "\n",
    "Comparing to not downsampling or upsampling, the overall accuracy decreased from the test set of 0.849 to around 0.8. This accuracy is similar to the constant model. However, the F1 score improved slightly from 0.570 to 0.596.\n",
    "\n",
    "Overall, the parameters used here for a Decision Tree model indicates that this may not be a good model to use for this particular data set based on the metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next section is on training Logistic Regression model with the downsampled or upsampled training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with downsampled training data set best solver: lbfgs\n",
      "Accuracy on training set: 0.716, validation set: 0.701, test set: 0.699\n",
      "Confusion matrix: \n",
      "[[1120  462]\n",
      " [ 137  281]]\n",
      "Recall: 0.672, Precision: 0.378, F1: 0.484\n",
      "Constant model accuracy score: 0.791\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression with downsampled training data set\n",
    "best_score = 0\n",
    "best_solver = ''\n",
    "solvers = ['lbfgs', 'liblinear', 'newton-cg']\n",
    "for solv in solvers:\n",
    "    model = LogisticRegression(random_state=12345, solver=solv)\n",
    "    model.fit(features_train_downsampled, target_train_downsampled)\n",
    "    score_valid = model.score(features_valid, target_valid)\n",
    "    if score_valid > best_score:\n",
    "        best_score = score_valid\n",
    "        best_solver = solv\n",
    "\n",
    "# Use highest scoring model parameters to calculate metrics\n",
    "model_best = LogisticRegression(random_state=12345, solver=best_solver)\n",
    "model_best.fit(features_train_downsampled, target_train_downsampled)\n",
    "\n",
    "# Scoring accuracy on the different sets\n",
    "score_train = model_best.score(features_train, target_train)\n",
    "score_valid = model_best.score(features_valid, target_valid)\n",
    "score_test = model_best.score(features_test, target_test)\n",
    "\n",
    "# Calculating metrics\n",
    "predicted_valid = model_best.predict(features_valid) \n",
    "cf_matrix = confusion_matrix(target_valid, predicted_valid) # confusion matrix\n",
    "recall = recall_score(target_valid, predicted_valid) # recall\n",
    "precision = precision_score(target_valid, predicted_valid) # precision\n",
    "f1_sc = f1_score(target_valid, predicted_valid) # F1 score\n",
    "\n",
    "# Print output\n",
    "print(f'Logistic Regression with downsampled training data set best solver: {best_solver}')\n",
    "print(f'Accuracy on training set: {score_train:.3f}, validation set: {score_valid:.3f}, test set: {score_test:.3f}')\n",
    "print(f'Confusion matrix: \\n{cf_matrix}')\n",
    "print(f'Recall: {recall:.3f}, Precision: {precision:.3f}, F1: {f1_sc:.3f}')\n",
    "\n",
    "# Sanity check of the constant model\n",
    "print(f'Constant model accuracy score: {score_constant:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with upsampled data set best solver: lbfgs\n",
      "Accuracy on training set: 0.718, validation set: 0.702, test set: 0.698\n",
      "Confusion matrix: \n",
      "[[1119  463]\n",
      " [ 133  285]]\n",
      "Recall: 0.682, Precision: 0.381, F1: 0.489\n",
      "Constant model accuracy score: 0.791\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression with upsampled training data set\n",
    "best_score = 0\n",
    "best_solver = ''\n",
    "solvers = ['lbfgs', 'liblinear', 'newton-cg']\n",
    "for solv in solvers:\n",
    "    model = LogisticRegression(random_state=12345, solver=solv)\n",
    "    model.fit(features_train_upsampled, target_train_upsampled)\n",
    "    score_valid = model.score(features_valid, target_valid)\n",
    "    if score_valid > best_score:\n",
    "        best_score = score_valid\n",
    "        best_solver = solv\n",
    "\n",
    "# Use highest scoring model parameters to calculate metrics\n",
    "model_best = LogisticRegression(random_state=12345, solver=best_solver)\n",
    "model_best.fit(features_train_upsampled, target_train_upsampled)\n",
    "\n",
    "# Scoring accuracy on the different sets\n",
    "score_train = model_best.score(features_train, target_train)\n",
    "score_valid = model_best.score(features_valid, target_valid)\n",
    "score_test = model_best.score(features_test, target_test)\n",
    "\n",
    "# Calculating metrics\n",
    "predicted_valid = model_best.predict(features_valid) \n",
    "cf_matrix = confusion_matrix(target_valid, predicted_valid) # confusion matrix\n",
    "recall = recall_score(target_valid, predicted_valid) # recall\n",
    "precision = precision_score(target_valid, predicted_valid) # precision\n",
    "f1_sc = f1_score(target_valid, predicted_valid) # F1 score\n",
    "\n",
    "# Print output\n",
    "print(f'Logistic Regression with upsampled data set best solver: {best_solver}')\n",
    "print(f'Accuracy on training set: {score_train:.3f}, validation set: {score_valid:.3f}, test set: {score_test:.3f}')\n",
    "print(f'Confusion matrix: \\n{cf_matrix}')\n",
    "print(f'Recall: {recall:.3f}, Precision: {precision:.3f}, F1: {f1_sc:.3f}')\n",
    "\n",
    "# Sanity check of the constant model\n",
    "print(f'Constant model accuracy score: {score_constant:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the metrics between downsampled or upsampled data this time on a logistic regression model were similar in terms of the overall accuracy of the test set and the F1 metric. We also see a decrease in the accuracy compared to not balancing the classes, yet the F1 metric has increased. So far, this model is the worse as the accuracy is lower than the constant model score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to train the downsampled or upsampled data on a Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with downsampled training data best n_estimator value: 10, max_depth: 5\n",
      "Accuracy on training set: 0.798, validation set: 0.794, test set: 0.783\n",
      "Confusion matrix: \n",
      "[[1276  306]\n",
      " [ 106  312]]\n",
      "Recall: 0.746, Precision: 0.505, F1: 0.602\n",
      "Constant model accuracy score: 0.791\n"
     ]
    }
   ],
   "source": [
    "# Random forest with downsampled data\n",
    "best_score = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "for est in range(10, 81, 10):\n",
    "    for depth in range(5, 10):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        model.fit(features_train_downsampled, target_train_downsampled)\n",
    "        score_valid = model.score(features_valid, target_valid)\n",
    "        if score_valid > best_score:\n",
    "            best_score = score_valid\n",
    "            best_depth = depth\n",
    "            best_est = est\n",
    "\n",
    "# Use highest scoring model parameters to calculate metrics\n",
    "model_best = RandomForestClassifier(random_state=12345, n_estimators=best_est, max_depth=best_depth)\n",
    "model_best.fit(features_train_downsampled, target_train_downsampled)\n",
    "\n",
    "# Scoring accuracy on the different sets\n",
    "score_train = model_best.score(features_train, target_train)\n",
    "score_valid = model_best.score(features_valid, target_valid)\n",
    "score_test = model_best.score(features_test, target_test)\n",
    "\n",
    "# Calculating metrics\n",
    "predicted_valid = model_best.predict(features_valid) \n",
    "cf_matrix = confusion_matrix(target_valid, predicted_valid) # confusion matrix\n",
    "recall = recall_score(target_valid, predicted_valid) # recall\n",
    "precision = precision_score(target_valid, predicted_valid) # precision\n",
    "f1_sc = f1_score(target_valid, predicted_valid) # F1 score\n",
    "\n",
    "# Print output\n",
    "print(f'Random Forest with downsampled training data best n_estimator value: {best_est}, max_depth: {best_depth}')\n",
    "print(f'Accuracy on training set: {score_train:.3f}, validation set: {score_valid:.3f}, test set: {score_test:.3f}')\n",
    "print(f'Confusion matrix: \\n{cf_matrix}')\n",
    "print(f'Recall: {recall:.3f}, Precision: {precision:.3f}, F1: {f1_sc:.3f}')\n",
    "\n",
    "# Sanity check of the constant model\n",
    "print(f'Constant model accuracy score: {score_constant:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with upsampled training data best n_estimator value: 70, max_depth: 9\n",
      "Accuracy on training set: 0.889, validation set: 0.826, test set: 0.811\n",
      "Confusion matrix: \n",
      "[[1355  227]\n",
      " [ 122  296]]\n",
      "Recall: 0.708, Precision: 0.566, F1: 0.629\n",
      "Constant model accuracy score: 0.791\n"
     ]
    }
   ],
   "source": [
    "# Random forest with upsampled data\n",
    "best_score = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "for est in range(10, 81, 10):\n",
    "    for depth in range(5, 10):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        model.fit(features_train_upsampled, target_train_upsampled)\n",
    "        score_valid = model.score(features_valid, target_valid)\n",
    "        if score_valid > best_score:\n",
    "            best_score = score_valid\n",
    "            best_depth = depth\n",
    "            best_est = est\n",
    "\n",
    "# Use highest scoring model parameters to calculate metrics\n",
    "model_best = RandomForestClassifier(random_state=12345, n_estimators=best_est, max_depth=best_depth)\n",
    "model_best.fit(features_train_upsampled, target_train_upsampled)\n",
    "\n",
    "# Scoring accuracy on the different sets\n",
    "score_train = model_best.score(features_train, target_train)\n",
    "score_valid = model_best.score(features_valid, target_valid)\n",
    "score_test = model_best.score(features_test, target_test)\n",
    "\n",
    "# Calculating metrics\n",
    "predicted_valid = model_best.predict(features_valid) \n",
    "cf_matrix = confusion_matrix(target_valid, predicted_valid) # confusion matrix\n",
    "recall = recall_score(target_valid, predicted_valid) # recall\n",
    "precision = precision_score(target_valid, predicted_valid) # precision\n",
    "f1_sc = f1_score(target_valid, predicted_valid) # F1 score\n",
    "\n",
    "# Print output\n",
    "print(f'Random Forest with upsampled training data best n_estimator value: {best_est}, max_depth: {best_depth}')\n",
    "print(f'Accuracy on training set: {score_train:.3f}, validation set: {score_valid:.3f}, test set: {score_test:.3f}')\n",
    "print(f'Confusion matrix: \\n{cf_matrix}')\n",
    "print(f'Recall: {recall:.3f}, Precision: {precision:.3f}, F1: {f1_sc:.3f}')\n",
    "\n",
    "# Sanity check of the constant model\n",
    "print(f'Constant model accuracy score: {score_constant:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing for random forest with the upsampled data seems to have the best result. The accuracy of the test set is higher than the constant model. And the F1 score has increased to above the target goal of 0.59."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model to predict whether customers will leave the bank will be displayed below, from the optimized parameters explored and described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.811\n",
      "Confusion matrix: \n",
      "[[1331  246]\n",
      " [ 131  292]]\n",
      "Recall: 0.690, Precision: 0.543, F1: 0.608\n"
     ]
    }
   ],
   "source": [
    "# Training best model\n",
    "model_best = RandomForestClassifier(random_state=12345, n_estimators=70, max_depth=9)\n",
    "model_best.fit(features_train_upsampled, target_train_upsampled)\n",
    "predicted_test = model_best.predict(features_test) \n",
    "\n",
    "# Scoring accuracy on test set\n",
    "score_test = accuracy_score(target_test, predicted_test)\n",
    "\n",
    "# Calculating metrics on the test set\n",
    "cf_matrix = confusion_matrix(target_test, predicted_test) # confusion matrix\n",
    "recall = recall_score(target_test, predicted_test) # recall\n",
    "precision = precision_score(target_test, predicted_test) # precision\n",
    "f1_sc = f1_score(target_test, predicted_test) # F1 score\n",
    "\n",
    "# Print output\n",
    "print(f'Accuracy on test set: {score_test:.3f}')\n",
    "print(f'Confusion matrix: \\n{cf_matrix}')\n",
    "print(f'Recall: {recall:.3f}, Precision: {precision:.3f}, F1: {f1_sc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting ROC curve for the best model\n",
    "probabilities_valid = model_best.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(target_test, probabilities_one_valid)\n",
    "plt.figure()\n",
    "# ROC curve for random model (looks like a straight line)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC is: 0.8531655550908374\n"
     ]
    }
   ],
   "source": [
    "# Calculate AUC-ROC\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_valid)\n",
    "print(f'AUC-ROC is: {auc_roc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and discussion\n",
    "\n",
    "The best model was determined to be a random forest model and the quality was improved by upsampling the data and improving the class imbalance. \n",
    "\n",
    "The resulting metrics had an accuracy of 0.811, F1 score of 0.608, and AUC-ROC of 0.853.\n",
    "\n",
    "F1 score is a score that ranges from 0 to 1, where 0 is the worse and 1 is the best possible score. It is evaluated from both the recall and precision metrics. It was achieved to have a F1 score greater than 0.59 as the target.\n",
    "\n",
    "AUC-ROC or aurea under the curve for receiver operating characteristic, this score ranges from 0.5 to 1, where 0.5 means the model is as good as random, and where 1 is the best score. This metric is the relationship between the true positive rate (TPR) and the false positive rate (FPR) of the model. Having a AUC-ROC of 0.853 means that our model is better than random, but not perfect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
